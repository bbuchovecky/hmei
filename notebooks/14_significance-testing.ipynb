{
 "cells": [
  {
   "cell_type": "raw",
   "id": "996dbee0-b8b4-4093-be6b-74f23cbbac5a",
   "metadata": {},
   "source": [
    "Project:      HMEI Summer Internship / Spring JP\n",
    "Author:       Benjamin Buchovecky\n",
    "Created:      3/31/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e79ee-69d0-408c-bcaf-ad657a4304fe",
   "metadata": {},
   "source": [
    "# Significance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e0587e-5856-4c7d-bac2-135091df08a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import scipy.stats as stats\n",
    "import esmtools.stats as esmstats\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c15b4e0-3726-4cb4-a94a-4b7997060d61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def open_metric(var, reg, metric, timescale='monthly', ens_type=''):\n",
    "    \n",
    "    writedir = '/home/bbuchovecky/storage/so_predict_derived/'\n",
    "    \n",
    "    if metric == 'clim':\n",
    "        subdir = 'CTRL/'+var.upper()+'/'\n",
    "        filename = var.lower()+'_ts_'+reg+'_'+metric+'.nc'\n",
    "    \n",
    "    if metric == 'anom' or metric == 'mean' or (metric == 'var' and timescale == 'monthly'):\n",
    "        subdir = 'CTRL/'+var.upper()+'/'\n",
    "        filename = var.lower()+'_ts_'+reg+'_'+timescale+'_'+metric+'.nc'\n",
    "    \n",
    "    if metric.lower() == 'ppp':\n",
    "        subdir = 'PPP/'+var.upper()+'/'\n",
    "        if ens_type != '':\n",
    "            ens_type += '_'\n",
    "        filename = var.lower()+'_ts_'+reg+'_'+timescale+'_'+ens_type+'ppp.nc'\n",
    "        \n",
    "    return xr.open_dataset(writedir+subdir+filename)\n",
    "\n",
    "def get_plotting_labels():\n",
    "    with open('/home/bbuchovecky/storage/so_predict_derived/plotting_dicts.pkl','rb') as handle:\n",
    "        plotting_dicts = pkl.load(handle)\n",
    "    \n",
    "    reg_names = plotting_dicts['reg_names']\n",
    "    var_abbrv_names = plotting_dicts['var_abbrv_names']\n",
    "    abbrv_month_names = plotting_dicts['abbrv_month_names']\n",
    "    month_letters = plotting_dicts['month_letters']\n",
    "    \n",
    "    return reg_names, var_abbrv_names, abbrv_month_names, month_letters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf0650f-a685-4c8a-a668-cb2b9392d387",
   "metadata": {},
   "source": [
    "## PM Experiment\n",
    "\n",
    "We use an $F$-test, so we first need to estimate the effective degrees of freedom.\n",
    "\n",
    "### PM ensemble\n",
    "6 start years ($M=6$) each with 40 ensemble members ($N=40$)\n",
    "\n",
    "$\\text{DOF}=M\\times N-1=6\\times 40 -1=239$\n",
    "\n",
    "### Control run\n",
    "300 years, equivalent to 300 samples per month, but we need to account for autocorrelation using [Bretherton et al. (1999)](https://doi-org.ezproxy.princeton.edu/10.1175/1520-0442(1999)012<1990:TENOSD>2.0.CO;2).\n",
    "\n",
    "> Different ‘‘realizations’’ would now correspond to independent sets of $T$ observations.\n",
    "\n",
    "> Following the approach of section 4b of looking at the distribution of the sample covariance between two unrelated time series, one can derive an analogous formula for the ESS appropriate for significance tests of the correlation between two times series $X_i$ and $Y_i$ with different autocorrelation sequences $\\rho_\\tau^X$ and $\\rho_\\tau^Y$:\n",
    "$$\n",
    "T_{XY}^*=\\frac{T}{\\sum\\limits_{\\tau=-(T-1)}^{(T-1)} (1-|\\tau|/T)\\rho_\\tau^X\\rho_\\tau^Y}\n",
    "$$\n",
    "\n",
    "For the control run, we are accounting for autocorrelation so the equation from Bretherton et al. (1999) becomes the following:\n",
    "$$\n",
    "T_{XX}^*=\\frac{T}{\\sum\\limits_{\\tau=-(T-1)}^{(T-1)} (1-|\\tau|/T)\\left(\\rho_\\tau^X\\right)^2}\n",
    "$$\n",
    "Each month (300 samples) will have its own $T^*$ value, but we will simplify this by choosing the most conservative value (lowest $T^*$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d055bd4a-a3c7-44fc-bb56-d3f29d802be0",
   "metadata": {},
   "source": [
    "### Function for computing $T^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8603f1b4-ab5c-4270-9278-141eb76a2c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Tstar(ts1, ts2, T=300, return_corr=False):\n",
    "    assert len(ts1) == len(ts2) == T\n",
    "    cumsum = 0\n",
    "    \n",
    "    corr_rho_1 = np.zeros(2*T-3)\n",
    "    corr_rho_2 = np.zeros(2*T-3)\n",
    "    \n",
    "    ## compute demoninator --> tau = [-298,298] since stats.pearsonr needs arrays with size >=2 \n",
    "#     for i,tau in enumerate(range(-T+2,T-2+1)):\n",
    "    for i,tau in enumerate(range(-10,10+1)):\n",
    "        coeff = 1 - (abs(tau)/T)\n",
    "        \n",
    "        if tau < 0:\n",
    "            rho_1 = stats.pearsonr(ts1[:tau], ts1[-tau:])[0] ## the [0] index just grabs the Pearson corr coeff and ignores the p-value\n",
    "            rho_2 = stats.pearsonr(ts2[:tau], ts2[-tau:])[0]\n",
    "        if tau == 0:\n",
    "            rho_1 = stats.pearsonr(ts1, ts1)[0]\n",
    "            rho_2 = stats.pearsonr(ts2, ts2)[0]\n",
    "        if tau > 0:\n",
    "            rho_1 = stats.pearsonr(ts1[tau:], ts1[:-tau])[0]\n",
    "            rho_2 = stats.pearsonr(ts2[tau:], ts2[:-tau])[0]\n",
    "            \n",
    "        corr_rho_1[i] = rho_1\n",
    "        corr_rho_2[i] = rho_2\n",
    "            \n",
    "        cumsum += coeff * rho_1 * rho_2\n",
    "    \n",
    "    ## return floor T* and autocorrelation vectors\n",
    "    if return_corr:\n",
    "        return corr_rho_1, corr_rho_2, T // cumsum\n",
    "    \n",
    "    ## return floor T*\n",
    "    if not return_corr:\n",
    "        return T // cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e5f935-3356-4a48-a592-3ff7bb84e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_PM_ctrl_run_Tstar(var, return_arr=False):\n",
    "    '''\n",
    "    Returns\n",
    "    -------\n",
    "    Tstar : array-like\n",
    "        An array of dim 12x6 with Tstar for each month and region [month x region]\n",
    "    '''\n",
    "    ts = open_metric(var,'so','anom')\n",
    "    Tstar = np.empty((12,6))\n",
    "    \n",
    "    print(ts.data_vars)\n",
    "    \n",
    "    for im,m in enumerate(range(12)):\n",
    "        for ireg,reg in enumerate(ts.data_vars):\n",
    "            Tstar[im,ireg] = compute_Tstar(ts[reg].values[m::12],ts[reg].values[m::12])\n",
    "            \n",
    "    if return_arr:\n",
    "        return Tstar,Tstar.min(axis=0),Tstar.min()\n",
    "    if not return_arr:\n",
    "        return Tstar.min(axis=0),Tstar.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e00d3185-d80a-4652-890c-d2dd38f01810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data variables:\n",
      "    SouthernOcean  (month) float64 ...\n",
      "    Weddell        (month) float64 ...\n",
      "    Indian         (month) float64 ...\n",
      "    WestPacific    (month) float64 ...\n",
      "    Ross           (month) float64 ...\n",
      "    AmundBell      (month) float64 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[195., 150., 263., 285., 227., 255.],\n",
       "        [188., 194., 277., 289., 223., 207.],\n",
       "        [201., 182., 271., 255., 207., 242.],\n",
       "        [256., 233., 274., 272., 283., 274.],\n",
       "        [283., 270., 293., 261., 268., 280.],\n",
       "        [285., 268., 274., 288., 282., 281.],\n",
       "        [267., 270., 280., 291., 253., 284.],\n",
       "        [266., 264., 270., 281., 279., 256.],\n",
       "        [193., 141., 228., 251., 269., 274.],\n",
       "        [176.,  78., 195., 228., 264., 278.],\n",
       "        [ 78.,  53., 222., 145., 136., 200.],\n",
       "        [131.,  87., 267., 281., 199., 197.]]),\n",
       " array([ 78.,  53., 195., 145., 136., 197.]),\n",
       " 53.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_PM_ctrl_run_Tstar('NPP', return_arr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97a1364-5be9-406b-955a-9b09fa830503",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data variables:\n",
      "    SouthernOcean  (month) float64 ...\n",
      "    Weddell        (month) float64 ...\n",
      "    Indian         (month) float64 ...\n",
      "    WestPacific    (month) float64 ...\n",
      "    Ross           (month) float64 ...\n",
      "    AmundBell      (month) float64 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[226., 169., 285., 284., 255., 271.],\n",
       "        [243., 228., 275., 287., 265., 250.],\n",
       "        [209., 207., 292., 272., 251., 278.],\n",
       "        [208., 141., 286., 280., 226., 275.],\n",
       "        [210., 118., 291., 280., 247., 246.],\n",
       "        [156.,  78., 276., 260., 227., 240.],\n",
       "        [102.,  56., 254., 209., 202., 212.],\n",
       "        [ 64.,  48., 201., 135., 190., 196.],\n",
       "        [ 50.,  43., 145., 102., 187., 159.],\n",
       "        [ 48.,  42., 130.,  78., 213., 161.],\n",
       "        [ 63.,  49., 163.,  96., 255., 170.],\n",
       "        [111.,  61., 212., 220., 230., 140.]]),\n",
       " array([ 48.,  42., 130.,  78., 187., 140.]),\n",
       " 42.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_PM_ctrl_run_Tstar('SIE', return_arr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a11b4f-fed8-409e-a90d-664b5211be80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data variables:\n",
      "    SouthernOcean  (month) float64 ...\n",
      "    Weddell        (month) float64 ...\n",
      "    Indian         (month) float64 ...\n",
      "    WestPacific    (month) float64 ...\n",
      "    Ross           (month) float64 ...\n",
      "    AmundBell      (month) float64 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[272., 240., 280., 283., 266., 292.],\n",
       "        [276., 283., 283., 277., 280., 271.],\n",
       "        [293., 264., 274., 275., 273., 287.],\n",
       "        [281., 278., 284., 275., 282., 281.],\n",
       "        [274., 271., 289., 265., 291., 263.],\n",
       "        [281., 268., 273., 282., 279., 280.],\n",
       "        [221., 151., 251., 275., 282., 278.],\n",
       "        [100.,  60., 212., 184., 240., 275.],\n",
       "        [ 68.,  48., 148., 180., 235., 260.],\n",
       "        [ 81.,  52., 158., 162., 203., 246.],\n",
       "        [101.,  79., 275., 185., 254., 241.],\n",
       "        [205., 151., 278., 283., 276., 267.]]),\n",
       " array([ 68.,  48., 148., 162., 203., 241.]),\n",
       " 48.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_PM_ctrl_run_Tstar('SFC_IRR', return_arr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbbdb8a6-87fe-4f30-9109-5ff85d37befd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data variables:\n",
      "    SouthernOcean  (month) float64 ...\n",
      "    Weddell        (month) float64 ...\n",
      "    Indian         (month) float64 ...\n",
      "    WestPacific    (month) float64 ...\n",
      "    Ross           (month) float64 ...\n",
      "    AmundBell      (month) float64 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[283., 293., 270., 288., 287., 282.],\n",
       "        [274., 291., 267., 266., 271., 265.],\n",
       "        [279., 288., 277., 274., 285., 289.],\n",
       "        [283., 285., 282., 283., 284., 292.],\n",
       "        [290., 258., 264., 288., 288., 282.],\n",
       "        [183., 164., 256., 268., 256., 265.],\n",
       "        [ 71.,  72., 153., 266., 224., 229.],\n",
       "        [ 54.,  57.,  92., 239., 206., 205.],\n",
       "        [ 58.,  66.,  62., 212., 226., 255.],\n",
       "        [ 81.,  89.,  62., 269., 239., 275.],\n",
       "        [261., 250., 261., 287., 286., 290.],\n",
       "        [285., 283., 294., 279., 287., 290.]]),\n",
       " array([ 54.,  57.,  62., 212., 206., 205.]),\n",
       " 54.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_PM_ctrl_run_Tstar('MLD', return_arr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9a1ad2c-ac8d-460c-a469-f8db10d57400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data variables:\n",
      "    SouthernOcean  (month) float64 ...\n",
      "    Weddell        (month) float64 ...\n",
      "    Indian         (month) float64 ...\n",
      "    WestPacific    (month) float64 ...\n",
      "    Ross           (month) float64 ...\n",
      "    AmundBell      (month) float64 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[248., 158., 265., 274., 241., 294.],\n",
       "        [275., 250., 257., 283., 267., 287.],\n",
       "        [273., 269., 257., 268., 260., 290.],\n",
       "        [265., 292., 279., 270., 284., 279.],\n",
       "        [280., 240., 248., 256., 285., 268.],\n",
       "        [270., 196., 284., 260., 255., 271.],\n",
       "        [257., 168., 269., 279., 244., 270.],\n",
       "        [252., 124., 215., 282., 275., 266.],\n",
       "        [260., 135., 213., 274., 274., 283.],\n",
       "        [270., 274., 218., 285., 263., 275.],\n",
       "        [276., 241., 284., 277., 277., 276.],\n",
       "        [250., 118., 244., 269., 279., 281.]]),\n",
       " array([248., 118., 213., 256., 241., 266.]),\n",
       " 118.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_PM_ctrl_run_Tstar('SFC_CHL', return_arr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6181b57-d602-4ab4-a3fb-cea1c8b290d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data variables:\n",
      "    SouthernOcean  (month) float64 ...\n",
      "    Weddell        (month) float64 ...\n",
      "    Indian         (month) float64 ...\n",
      "    WestPacific    (month) float64 ...\n",
      "    Ross           (month) float64 ...\n",
      "    AmundBell      (month) float64 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[241., 122., 243., 275., 232., 280.],\n",
       "        [252., 105., 255., 287., 221., 276.],\n",
       "        [258., 174., 259., 288., 280., 249.],\n",
       "        [278., 263., 265., 283., 287., 280.],\n",
       "        [287., 263., 269., 257., 282., 274.],\n",
       "        [274., 222., 285., 266., 258., 274.],\n",
       "        [266., 201., 269., 285., 252., 277.],\n",
       "        [275., 208., 244., 283., 289., 264.],\n",
       "        [269., 281., 256., 269., 272., 280.],\n",
       "        [274., 266., 277., 282., 270., 276.],\n",
       "        [234., 128., 269., 261., 273., 275.],\n",
       "        [290., 233., 268., 280., 283., 267.]]),\n",
       " array([234., 105., 243., 257., 221., 249.]),\n",
       " 105.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_PM_ctrl_run_Tstar('SFC_BIOMASS', return_arr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634dc9c3-4fb9-4423-bcc1-54e5088cfd81",
   "metadata": {},
   "source": [
    "### Computing the $F$-test critical value at different confidence levels\n",
    "\n",
    "`scipy.stats.f.ppf(q, dfn, dfd)` is the inverse CDF (i.e., the quantile function) which we can use to generate the critical values for an $F$ test with `dfn` as the DOF in the numerator and `dfd` as the DOF in the denominator.\n",
    "\n",
    "[scipy.stats.rv_continuous.ppf](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.ppf.html#scipy.stats.rv_continuous.ppf) - Percent point function (inverse of cdf) at $q$ of the given RV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf229d-2b09-4e9e-865a-bce93c1b601f",
   "metadata": {},
   "source": [
    "### Performing the $F$ test\n",
    "[F Statistic/F value](https://www.statisticshowto.com/probability-and-statistics/f-statistic-value-test/#WhatisF)\n",
    "\n",
    "[F Test](https://www.statisticshowto.com/probability-and-statistics/hypothesis-testing/f-test/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b85966a-9029-43a1-aec8-9324da38102f",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "Here, we calculate the effective DOFs ($T^*$) and then use a $t$-test to assess significance.\n",
    "$$\n",
    "T_{XY}^*=\\frac{T}{\\sum\\limits_{\\tau=-(T-1)}^{(T-1)} (1-|\\tau|/T)\\rho_\\tau^X\\rho_\\tau^Y}\n",
    "$$\n",
    "\n",
    "Formula for converting correlation coefficient $r$ to $t$-test value:\n",
    "$$\n",
    "\\text{t-value}=r\\sqrt{\\frac{T^*}{1-r^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b726b108-0bea-49e5-99ce-1f7bfc27369d",
   "metadata": {},
   "source": [
    "### Compute $T^*$ for correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36026675-6d02-4181-85ac-dc820b0d775f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_corr_Tstar(predictor, predictand, maxlag, return_arr=False):\n",
    "    ## convert DataArray to NumPy array\n",
    "    predictor = predictor.values\n",
    "    predictand = predictand.values\n",
    "    \n",
    "    assert predictor.size == predictand.size, 'predictor and predictand have different lengths'\n",
    "    N = predictor.size\n",
    "\n",
    "    ## rows are different init months, cols are different lags\n",
    "    Tstar_matrix = np.zeros((abs(maxlag)+1, 12))\n",
    "\n",
    "    init_matrix = np.zeros((abs(maxlag)+1, 12))\n",
    "    lag_matrix = np.zeros((abs(maxlag)+1, 12))\n",
    "\n",
    "    lag_values = np.arange(maxlag, 1)\n",
    "    for (it,init) in enumerate(range(0,12)):\n",
    "        for (ig,lag) in enumerate(lag_values):   \n",
    "            trim = 12*((abs(lag)-1)//12+1)\n",
    "            init_matrix[ig][it] = init\n",
    "            lag_matrix[ig][it] = lag\n",
    "\n",
    "            if lag == 0:\n",
    "                tmp_predictand = predictand[init:N:12]\n",
    "                tmp_predictor = predictor[init:N:12]\n",
    "\n",
    "            else:\n",
    "                tmp_predictand = predictand[init+trim:N:12]\n",
    "                tmp_predictor = predictor[init+trim+lag:N-trim+init:12]\n",
    "\n",
    "            Tstar_matrix[ig][it] = compute_Tstar(tmp_predictand, tmp_predictor, T=min([len(tmp_predictand), len(tmp_predictor)]))\n",
    "            \n",
    "    min_Tstar = Tstar_matrix.min()\n",
    "        \n",
    "    if return_arr:\n",
    "        return Tstar_matrix, min_Tstar\n",
    "    if not return_arr:\n",
    "        return min_Tstar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb9d61-6e87-4d8d-940e-6791740ee90d",
   "metadata": {},
   "source": [
    "### SIE predicting NPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d132f070-4fab-4fcc-b49a-a2f8a796869f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictor = SIE\n",
      "predictand = NPP\n",
      "\n",
      "Weddell  --> T* = 47.0\n",
      "Indian  --> T* = 166.0\n",
      "WestPacific  --> T* = 112.0\n",
      "SouthernOcean  --> T* = 62.0\n",
      "Ross  --> T* = 166.0\n",
      "AmundBell  --> T* = 176.0\n"
     ]
    }
   ],
   "source": [
    "predictor = 'SIE'\n",
    "predictand = 'NPP'\n",
    "maxlag = -24\n",
    "region_list = ['Weddell', 'Indian', 'WestPacific', 'SouthernOcean', 'Ross', 'AmundBell']   \n",
    "sie_pred_npp_Tstar = np.zeros(6)\n",
    "\n",
    "print('predictor =',predictor)\n",
    "print('predictand =',predictand)\n",
    "print()\n",
    "for (ireg,reg) in enumerate(region_list):  \n",
    "    ts_predictor = open_metric(predictor, 'so', 'anom')[reg]\n",
    "    ts_predictand = open_metric(predictand, 'so', 'anom')[reg]\n",
    "    min_Tstar = compute_corr_Tstar(ts_predictor, ts_predictand, maxlag=maxlag)\n",
    "    print(reg,' --> T* = {t:.1f}'.format(t=min_Tstar))\n",
    "    sie_pred_npp_Tstar[ireg] = min_Tstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6deec4d9-002c-48ce-a5e2-3472080cd7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 47., 166., 112.,  62., 166., 176.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sie_pred_npp_Tstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03afec29-97ab-42be-855f-25ef63829ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weddell\n",
      "T* = 47.0\n",
      "critical t-value = 2.0030\n",
      "\n",
      "Indian\n",
      "T* = 166.0\n",
      "critical t-value = 1.9670\n",
      "\n",
      "WestPacific\n",
      "T* = 112.0\n",
      "critical t-value = 1.9730\n",
      "\n",
      "SouthernOcean\n",
      "T* = 62.0\n",
      "critical t-value = 1.9910\n",
      "\n",
      "Ross\n",
      "T* = 166.0\n",
      "critical t-value = 1.9670\n",
      "\n",
      "AmundBell\n",
      "T* = 176.0\n",
      "critical t-value = 1.9650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "region_list = ['Weddell', 'Indian', 'WestPacific', 'SouthernOcean', 'Ross', 'AmundBell'] \n",
    "sie_pred_npp_tcrit = np.zeros(6)\n",
    "\n",
    "for it,t in enumerate(sie_pred_npp_Tstar):\n",
    "    for tcrit in np.linspace(1,3,1000):\n",
    "        if np.round(stats.t.cdf(tcrit,t), 3) == 0.975:\n",
    "            print(region_list[it])\n",
    "            print('T* = {a:.1f}'.format(a=t))\n",
    "            print('critical t-value = {a:.4f}\\n'.format(a=tcrit))\n",
    "            sie_pred_npp_tcrit[it] = tcrit\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d74266de-2f06-44c5-9d80-db7a10ccabc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weddell\n",
      "T* = 47.0\n",
      "critical t-value = 2.0030\n",
      "corr coeff threshold = 0.2803\n",
      "\n",
      "Indian\n",
      "T* = 166.0\n",
      "critical t-value = 1.9670\n",
      "corr coeff threshold = 0.1512\n",
      "\n",
      "WestPacific\n",
      "T* = 112.0\n",
      "critical t-value = 1.9730\n",
      "corr coeff threshold = 0.1832\n",
      "\n",
      "SouthernOcean\n",
      "T* = 62.0\n",
      "critical t-value = 1.9910\n",
      "corr coeff threshold = 0.2452\n",
      "\n",
      "Ross\n",
      "T* = 166.0\n",
      "critical t-value = 1.9670\n",
      "corr coeff threshold = 0.1512\n",
      "\n",
      "AmundBell\n",
      "T* = 176.0\n",
      "critical t-value = 1.9650\n",
      "corr coeff threshold = 0.1461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "region_list = ['Weddell', 'Indian', 'WestPacific', 'SouthernOcean', 'Ross', 'AmundBell'] \n",
    "sie_pred_npp_rthresh = np.zeros(6)\n",
    "\n",
    "for i,tcrit in enumerate(sie_pred_npp_tcrit):\n",
    "    for r in np.linspace(0,1,1000):\n",
    "        if np.round(r * np.sqrt(sie_pred_npp_Tstar[i] / (1 - r**2)), 2) == np.round(tcrit, 2):\n",
    "            print(region_list[i])\n",
    "            print('T* = {a:.1f}'.format(a=sie_pred_npp_Tstar[i]))\n",
    "            print('critical t-value = {a:.4f}'.format(a=tcrit))\n",
    "            print('corr coeff threshold = {a:.4f}\\n'.format(a=r))\n",
    "            sie_pred_npp_rthresh[i] = r\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "521c9cdb-debc-4231-b1f5-fd979117181c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28028028, 0.15115115, 0.18318318, 0.24524525, 0.15115115,\n",
       "       0.14614615])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sie_pred_npp_rthresh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef58bd-dc0b-4364-8091-3ce26ad17ccb",
   "metadata": {},
   "source": [
    "### SFC_IRR predicting NPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6801d483-6b1c-43d1-a66b-47714221f894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictor = SFC_IRR\n",
      "predictand = NPP\n",
      "\n",
      "Weddell  --> T* = 51.0\n",
      "Indian  --> T* = 173.0\n",
      "WestPacific  --> T* = 156.0\n",
      "SouthernOcean  --> T* = 73.0\n",
      "Ross  --> T* = 170.0\n",
      "AmundBell  --> T* = 227.0\n"
     ]
    }
   ],
   "source": [
    "predictor = 'SFC_IRR'\n",
    "predictand = 'NPP'\n",
    "maxlag = -24\n",
    "region_list = ['Weddell', 'Indian', 'WestPacific', 'SouthernOcean', 'Ross', 'AmundBell']\n",
    "irr_pred_npp_Tstar = np.zeros(6)\n",
    "\n",
    "print('predictor =',predictor)\n",
    "print('predictand =',predictand)\n",
    "print()\n",
    "for (ireg,reg) in enumerate(region_list):  \n",
    "    ts_predictor = open_metric(predictor, 'so', 'anom')[reg]\n",
    "    ts_predictand = open_metric(predictand, 'so', 'anom')[reg]\n",
    "    min_Tstar = compute_corr_Tstar(ts_predictor, ts_predictand, maxlag=maxlag)\n",
    "    print(reg,' --> T* = {t:.1f}'.format(t=min_Tstar))\n",
    "    irr_pred_npp_Tstar[ireg] = min_Tstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90fcb079-6fb4-494a-a284-764a8ffe7728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 51., 173., 156.,  73., 170., 227.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irr_pred_npp_Tstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "398c3915-ebc0-48d5-bdd5-40acf3d013bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weddell\n",
      "T* = 51.0\n",
      "critical t-value = 1.9990\n",
      "\n",
      "Indian\n",
      "T* = 173.0\n",
      "critical t-value = 1.9670\n",
      "\n",
      "WestPacific\n",
      "T* = 156.0\n",
      "critical t-value = 1.9670\n",
      "\n",
      "SouthernOcean\n",
      "T* = 73.0\n",
      "critical t-value = 1.9850\n",
      "\n",
      "Ross\n",
      "T* = 170.0\n",
      "critical t-value = 1.9670\n",
      "\n",
      "AmundBell\n",
      "T* = 227.0\n",
      "critical t-value = 1.9630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "region_list = ['Weddell', 'Indian', 'WestPacific', 'SouthernOcean', 'Ross', 'AmundBell'] \n",
    "irr_pred_npp_tcrit = np.zeros(6)\n",
    "\n",
    "for it,t in enumerate(irr_pred_npp_Tstar):\n",
    "    for tcrit in np.linspace(1,3,1000):\n",
    "        if np.round(stats.t.cdf(tcrit,t), 3) == 0.975:\n",
    "            print(region_list[it])\n",
    "            print('T* = {a:.1f}'.format(a=t))\n",
    "            print('critical t-value = {a:.4f}\\n'.format(a=tcrit))\n",
    "            irr_pred_npp_tcrit[it] = tcrit\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44e2b509-425f-4aaf-8ffe-f14fd8763c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weddell\n",
      "T* = 51.0\n",
      "critical t-value = 1.9990\n",
      "corr coeff threshold = 0.2693\n",
      "\n",
      "Indian\n",
      "T* = 173.0\n",
      "critical t-value = 1.9670\n",
      "corr coeff threshold = 0.1481\n",
      "\n",
      "WestPacific\n",
      "T* = 156.0\n",
      "critical t-value = 1.9670\n",
      "corr coeff threshold = 0.1562\n",
      "\n",
      "SouthernOcean\n",
      "T* = 73.0\n",
      "critical t-value = 1.9850\n",
      "corr coeff threshold = 0.2252\n",
      "\n",
      "Ross\n",
      "T* = 170.0\n",
      "critical t-value = 1.9670\n",
      "corr coeff threshold = 0.1491\n",
      "\n",
      "AmundBell\n",
      "T* = 227.0\n",
      "critical t-value = 1.9630\n",
      "corr coeff threshold = 0.1291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "region_list = ['Weddell', 'Indian', 'WestPacific', 'SouthernOcean', 'Ross', 'AmundBell'] \n",
    "irr_pred_npp_rthresh = np.zeros(6)\n",
    "\n",
    "for i,tcrit in enumerate(irr_pred_npp_tcrit):\n",
    "    for r in np.linspace(0,1,1000):\n",
    "        if np.round(r * np.sqrt(irr_pred_npp_Tstar[i] / (1 - r**2)), 2) == np.round(tcrit, 2):\n",
    "            print(region_list[i])\n",
    "            print('T* = {a:.1f}'.format(a=irr_pred_npp_Tstar[i]))\n",
    "            print('critical t-value = {a:.4f}'.format(a=tcrit))\n",
    "            print('corr coeff threshold = {a:.4f}\\n'.format(a=r))\n",
    "            irr_pred_npp_rthresh[i] = r\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1338fc23-afc0-44df-9264-148d8e1f244c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26926927, 0.14814815, 0.15615616, 0.22522523, 0.14914915,\n",
       "       0.12912913])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irr_pred_npp_rthresh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287e90b4-8e3d-42d7-be37-58ef1bf03d76",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98240a3-791f-4566-924e-1e4041b90523",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_t_stat(predictor, predictand):\n",
    "    ## convert DataArray to NumPy array\n",
    "    predictor = predictor.values\n",
    "    predictand = predictand.values\n",
    "    \n",
    "    ## rows are different init months, cols are different lags\n",
    "    eff_dof = np.zeros((abs(maxlag)+1, 12))\n",
    "    \n",
    "    for (it,init) in enumerate(range(0,12)):\n",
    "        for (ig,lag) in enumerate(range(0,12)):\n",
    "            \n",
    "            tmp_predictand = predictand[init:N:12]\n",
    "            tmp_predictor = predictor[init:N:12]\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f7f2b71-65bd-454b-b965-1242d13bc167",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def open_metric(var, reg, metric, timescale='monthly', ens_type=''):\n",
    "    \n",
    "    writedir = '/home/bbuchovecky/storage/so_predict_derived/'\n",
    "    \n",
    "    if metric == 'clim':\n",
    "        subdir = 'CTRL/'+var.upper()+'/'\n",
    "        filename = var.lower()+'_ts_'+reg+'_'+metric+'.nc'\n",
    "    \n",
    "    if metric == 'anom' or metric == 'mean' or (metric == 'var' and timescale == 'monthly'):\n",
    "        subdir = 'CTRL/'+var.upper()+'/'\n",
    "        filename = var.lower()+'_ts_'+reg+'_'+timescale+'_'+metric+'.nc'\n",
    "    \n",
    "    if metric.lower() == 'ppp':\n",
    "        subdir = 'PPP/'+var.upper()+'/'\n",
    "        if ens_type != '':\n",
    "            ens_type += '_'\n",
    "        filename = var.lower()+'_ts_'+reg+'_'+timescale+'_'+ens_type+'ppp.nc'\n",
    "        \n",
    "    return xr.open_dataset(writedir+subdir+filename)\n",
    "\n",
    "def get_plotting_labels():\n",
    "    with open('/home/bbuchovecky/storage/so_predict_derived/plotting_dicts.pkl','rb') as handle:\n",
    "        plotting_dicts = pkl.load(handle)\n",
    "    \n",
    "    reg_names = plotting_dicts['reg_names']\n",
    "    var_abbrv_names = plotting_dicts['var_abbrv_names']\n",
    "    abbrv_month_names = plotting_dicts['abbrv_month_names']\n",
    "    month_letters = plotting_dicts['month_letters']\n",
    "    var_su_names = plotting_dicts['var_su_names']\n",
    "    \n",
    "    return reg_names, var_abbrv_names, abbrv_month_names, month_letters, var_su_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aa1e5cc-4a4c-4185-8f61-409565377f97",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## predictor --> the field doing the predicting (e.g., SIE or SFC_IRR)\n",
    "## predictand --> the field being predicted (e.g., NPP)\n",
    "def compute_lagged_xcorr(predictor, predictand, maxlag):\n",
    "    ## convert DataArray to NumPy array\n",
    "    predictor = predictor.values\n",
    "    predictand = predictand.values\n",
    "    \n",
    "    assert predictor.size == predictand.size, 'predictor and predictand have different lengths'\n",
    "    N = predictor.size\n",
    "    \n",
    "    ## rows are different init months, cols are different lags\n",
    "    r_matrix = np.zeros((abs(maxlag)+1, 12))\n",
    "    p_matrix = np.zeros((abs(maxlag)+1, 12))\n",
    "\n",
    "    init_matrix = np.zeros((abs(maxlag)+1, 12))\n",
    "    lag_matrix = np.zeros((abs(maxlag)+1, 12))\n",
    "    \n",
    "    lag_values = np.arange(maxlag, 1)\n",
    "    for (it,init) in enumerate(range(0,12)):\n",
    "        for (ig,lag) in enumerate(lag_values):   \n",
    "            trim = 12*((abs(lag)-1)//12+1)\n",
    "            init_matrix[ig][it] = init\n",
    "            lag_matrix[ig][it] = lag\n",
    "            \n",
    "            if lag == 0:\n",
    "                tmp_predictand = predictand[init:N:12]\n",
    "                tmp_predictor = predictor[init:N:12]\n",
    "                \n",
    "            else:\n",
    "                tmp_predictand = predictand[init+trim:N:12]\n",
    "                tmp_predictor = predictor[init+trim+lag:N-trim+init:12]\n",
    "            \n",
    "            r_matrix[ig][it], p_matrix[ig][it] = stats.pearsonr(tmp_predictand, tmp_predictor)\n",
    "            \n",
    "    return r_matrix, p_matrix, init_matrix, lag_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
